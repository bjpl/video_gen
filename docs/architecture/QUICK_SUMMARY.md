# Architecture Analysis - Quick Summary

## TL;DR

**Architecture Score: 8.1/10** (Very Good)

The video_gen project uses a clean **Pipeline Architecture** with strong separation of concerns. Main issues are duplicate config/exception modules and external script dependencies‚Äîall fixable technical debt.

---

## Key Strengths ‚úÖ

1. **Pipeline Pattern** - Clean stage-based execution with resume capability
2. **Adapter Pattern** - Easy to add new input types (5 adapters implemented)
3. **Event-Driven** - Progress tracking via observer pattern
4. **State Management** - Production-ready persistence and resume
5. **Type Safety** - Good use of dataclasses and type hints
6. **Modular Design** - Clear separation of concerns

---

## Critical Issues üî¥

### Issue 1: Duplicate Configuration
- **Problem:** Two config modules (`config.py` and `shared/config.py`)
- **Impact:** Configuration fragmentation, maintenance burden
- **Fix:** Consolidate to `shared/config.py`, update all imports
- **Effort:** 1-2 days

### Issue 2: Duplicate Exceptions
- **Problem:** Two exception hierarchies (`exceptions.py` and `shared/exceptions.py`)
- **Impact:** Inconsistent error handling
- **Fix:** Consolidate to `shared/exceptions.py`
- **Effort:** 1 day

### Issue 3: External Script Dependencies
- **Problem:** `video_generator/unified.py` imports from `../../../scripts/`
- **Impact:** Breaks encapsulation, hard to test
- **Fix:** Move scene renderers to `video_gen/renderers/` module
- **Effort:** 2-3 days

---

## Architecture Patterns

### Primary Pattern: Pipeline (Sequential Stages)

```
Input ‚Üí Parsing ‚Üí Script Gen ‚Üí Audio Gen ‚Üí Video Gen ‚Üí Output
```

**Each stage:**
- Inherits from `Stage` base class
- Receives context dictionary
- Returns `StageResult`
- Emits progress events
- Can fail gracefully

### Supporting Patterns:

1. **Adapter Pattern** - Input adapters (document, YouTube, YAML, etc.)
2. **Singleton Pattern** - Global config instance
3. **Observer Pattern** - Event emitter for progress tracking
4. **State Pattern** - Task state with persistence

---

## Component Map

```
video_gen/
‚îú‚îÄ‚îÄ pipeline/          # Orchestration (411 LOC)
‚îú‚îÄ‚îÄ stages/            # 7 processing stages
‚îú‚îÄ‚îÄ input_adapters/    # 5 input types
‚îú‚îÄ‚îÄ shared/            # Models, config, exceptions
‚îú‚îÄ‚îÄ audio_generator/   # TTS audio (420 LOC)
‚îú‚îÄ‚îÄ video_generator/   # Video rendering (588 LOC)
‚îú‚îÄ‚îÄ content_parser/    # Markdown parsing (227 LOC)
‚îú‚îÄ‚îÄ script_generator/  # Narration generation (116 LOC)
‚îî‚îÄ‚îÄ output_handler/    # Export handling
```

**Total:** 41 files, 6,346 LOC

---

## Data Flow with Detailed Transformations

```
‚îå‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îê
‚îÇ                         DATA TRANSFORMATION FLOW                         ‚îÇ
‚îî‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îò

USER INPUT
  ‚îÇ
  ‚îÇ Various formats:
  ‚îÇ ‚Ä¢ Document (PDF, DOCX, MD, TXT)
  ‚îÇ ‚Ä¢ YouTube URL
  ‚îÇ ‚Ä¢ YAML configuration
  ‚îÇ ‚Ä¢ Python dictionary (programmatic)
  ‚îÇ ‚Ä¢ Interactive wizard input
  ‚îÇ
  ‚ñº
‚îå‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îê
‚îÇ Stage 1: InputAdapter       ‚îÇ  WHY: Normalize diverse inputs to common format
‚îÇ                             ‚îÇ
‚îÇ Input: Raw source           ‚îÇ  HOW: Strategy pattern with 5 adapters
‚îÇ Output: VideoConfig         ‚îÇ
‚îÇ                             ‚îÇ  DESIGN DECISION: Adapter pattern chosen for:
‚îÇ Transformation:             ‚îÇ  ‚Ä¢ Easy to add new input types
‚îÇ ‚Ä¢ Parse source format       ‚îÇ  ‚Ä¢ Encapsulates format-specific logic
‚îÇ ‚Ä¢ Extract structure         ‚îÇ  ‚Ä¢ Consistent output (VideoConfig)
‚îÇ ‚Ä¢ Apply defaults            ‚îÇ
‚îÇ ‚Ä¢ Create scenes             ‚îÇ  TRADE-OFF: Some duplication across adapters,
‚îÇ                             ‚îÇ             but better separation of concerns
‚îî‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îò
  ‚îÇ
  ‚îÇ VideoConfig {
  ‚îÇ   video_id: str
  ‚îÇ   title: str
  ‚îÇ   scenes: [SceneConfig, ...]
  ‚îÇ   accent_color: str
  ‚îÇ   voices: [str, ...]
  ‚îÇ }
  ‚îÇ
  ‚ñº
‚îå‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îê
‚îÇ Stage 2: ContentParser      ‚îÇ  WHY: Structure raw content for scene generation
‚îÇ                             ‚îÇ
‚îÇ Input: VideoConfig          ‚îÇ  HOW: Markdown/HTML parsing + structure detection
‚îÇ Output: ParsedContent       ‚îÇ
‚îÇ                             ‚îÇ  DESIGN DECISION: Parser extracts:
‚îÇ Transformation:             ‚îÇ  ‚Ä¢ Headings ‚Üí Title scenes
‚îÇ ‚Ä¢ Extract sections          ‚îÇ  ‚Ä¢ Lists ‚Üí List scenes
‚îÇ ‚Ä¢ Identify headings         ‚îÇ  ‚Ä¢ Code blocks ‚Üí Code comparison scenes
‚îÇ ‚Ä¢ Detect lists              ‚îÇ  ‚Ä¢ Quotes ‚Üí Quote scenes
‚îÇ ‚Ä¢ Extract code blocks       ‚îÇ
‚îÇ                             ‚îÇ  PERFORMANCE: ~1-5s for typical document
‚îî‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îò
  ‚îÇ
  ‚îÇ ParsedContent {
  ‚îÇ   sections: [Section, ...]
  ‚îÇ   templates: [SceneTemplate, ...]
  ‚îÇ   metadata: {pages, words, ...}
  ‚îÇ }
  ‚îÇ
  ‚ñº
‚îå‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îê
‚îÇ Stage 3: ScriptGenerator    ‚îÇ  WHY: Create engaging narration for each scene
‚îÇ                             ‚îÇ
‚îÇ Input: ParsedContent        ‚îÇ  HOW: Template-based + optional AI enhancement
‚îÇ Output: VideoConfig+Scripts ‚îÇ
‚îÇ                             ‚îÇ  DESIGN DECISION: Two-tier approach:
‚îÇ Transformation:             ‚îÇ  1. Base: Template-based (fast, predictable)
‚îÇ ‚Ä¢ Generate narration        ‚îÇ  2. Enhanced: AI-powered (slower, better quality)
‚îÇ ‚Ä¢ AI enhance (optional)     ‚îÇ
‚îÇ ‚Ä¢ Validate timing           ‚îÇ  TRADE-OFF: AI enhancement adds 2-10s per scene
‚îÇ ‚Ä¢ Check min/max duration    ‚îÇ             but significantly improves quality
‚îÇ                             ‚îÇ
‚îÇ                             ‚îÇ  PERFORMANCE: 10-30s total (without AI)
‚îî‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îò
  ‚îÇ
  ‚îÇ VideoConfig {
  ‚îÇ   scenes: [
  ‚îÇ     SceneConfig {
  ‚îÇ       narration: "Welcome to...",  ‚Üê NEW
  ‚îÇ       visual_content: {...},
  ‚îÇ       voice: "male",
  ‚îÇ       min_duration: 3.0,
  ‚îÇ       max_duration: 15.0
  ‚îÇ     }
  ‚îÇ   ]
  ‚îÇ }
  ‚îÇ
  ‚ñº
‚îå‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îê
‚îÇ Stage 4: AudioGenerator     ‚îÇ  WHY: Convert text to speech with timing data
‚îÇ                             ‚îÇ
‚îÇ Input: VideoConfig+Scripts  ‚îÇ  HOW: Edge TTS API + FFmpeg duration probe
‚îÇ Output: Audio Files+Timing  ‚îÇ
‚îÇ                             ‚îÇ  DESIGN DECISION: Edge TTS chosen because:
‚îÇ Transformation:             ‚îÇ  ‚Ä¢ Free, unlimited usage
‚îÇ For each scene:             ‚îÇ  ‚Ä¢ 27+ high-quality voices
‚îÇ   ‚Ä¢ Call TTS API            ‚îÇ  ‚Ä¢ Multi-language support
‚îÇ   ‚Ä¢ Save MP3                ‚îÇ  ‚Ä¢ Async API for parallelization
‚îÇ   ‚Ä¢ Measure duration        ‚îÇ
‚îÇ   ‚Ä¢ Update scene.audio_file ‚îÇ  TRADE-OFF: Network dependency (requires internet)
‚îÇ   ‚Ä¢ Check constraints       ‚îÇ             vs. Offline TTS (lower quality)
‚îÇ                             ‚îÇ
‚îÇ                             ‚îÇ  PERFORMANCE: 30s-2min for 10 scenes
‚îÇ                             ‚îÇ               (2-5s per scene)
‚îî‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îò
  ‚îÇ
  ‚îÇ AudioAssets {
  ‚îÇ   audio_dir: Path("audio/video_xyz_audio/")
  ‚îÇ   files: [
  ‚îÇ     scene_1.mp3 (4.2s),
  ‚îÇ     scene_2.mp3 (6.8s),
  ‚îÇ     ...
  ‚îÇ   ]
  ‚îÇ   timing_report: {
  ‚îÇ     total_duration: 120.5,
  ‚îÇ     warnings: ["Scene 3 truncated"],
  ‚îÇ     scenes: [...]
  ‚îÇ   }
  ‚îÇ }
  ‚îÇ
  ‚ñº
‚îå‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îê
‚îÇ Stage 5: VideoGenerator     ‚îÇ  WHY: Create visual representation of scenes
‚îÇ                             ‚îÇ
‚îÇ Input: AudioAssets+Config   ‚îÇ  HOW: PIL rendering + NumPy + FFmpeg encoding
‚îÇ Output: Video Segments      ‚îÇ
‚îÇ                             ‚îÇ  DESIGN DECISION: NumPy acceleration chosen for:
‚îÇ Transformation:             ‚îÇ  ‚Ä¢ 10x faster frame blending vs. pure PIL
‚îÇ For each scene:             ‚îÇ  ‚Ä¢ Smooth transitions (crossfade, slide)
‚îÇ   ‚Ä¢ Render keyframes (PIL)  ‚îÇ  ‚Ä¢ Memory-efficient batch processing
‚îÇ   ‚Ä¢ Apply transitions       ‚îÇ
‚îÇ   ‚Ä¢ Encode (FFmpeg+NVENC)   ‚îÇ  DESIGN DECISION: NVENC GPU encoding chosen:
‚îÇ   ‚Ä¢ Mux audio               ‚îÇ  ‚Ä¢ 3-5x faster than CPU encoding
‚îÇ   ‚Ä¢ Save MP4                ‚îÇ  ‚Ä¢ Lower quality loss
‚îÇ                             ‚îÇ  ‚Ä¢ Hardware acceleration
‚îÇ                             ‚îÇ
‚îÇ                             ‚îÇ  TRADE-OFF: Requires NVIDIA GPU
‚îÇ                             ‚îÇ             Falls back to CPU if unavailable
‚îÇ                             ‚îÇ
‚îÇ                             ‚îÇ  PERFORMANCE: 1-5min for 10 scenes
‚îÇ                             ‚îÇ               (varies by resolution/complexity)
‚îî‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îò
  ‚îÇ
  ‚îÇ VideoAssets {
  ‚îÇ   video_segments: [
  ‚îÇ     Path("video/scene_1.mp4"),
  ‚îÇ     Path("video/scene_2.mp4"),
  ‚îÇ     ...
  ‚îÇ   ]
  ‚îÇ   metadata: {
  ‚îÇ     total_frames: 3600,
  ‚îÇ     avg_bitrate: "2000k"
  ‚îÇ   }
  ‚îÇ }
  ‚îÇ
  ‚ñº
‚îå‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îê
‚îÇ Stage 6: OutputHandler      ‚îÇ  WHY: Finalize and organize deliverables
‚îÇ                             ‚îÇ
‚îÇ Input: Video Segments       ‚îÇ  HOW: FFmpeg concat + file organization
‚îÇ Output: Final Video+Metadata‚îÇ
‚îÇ                             ‚îÇ  DESIGN DECISION: Concat protocol chosen:
‚îÇ Transformation:             ‚îÇ  ‚Ä¢ Lossless merging (no re-encoding)
‚îÇ ‚Ä¢ Concatenate segments      ‚îÇ  ‚Ä¢ Fast (1-2s for 10 segments)
‚îÇ ‚Ä¢ Organize files            ‚îÇ  ‚Ä¢ Preserves quality
‚îÇ ‚Ä¢ Generate metadata         ‚îÇ
‚îÇ ‚Ä¢ Create timing report      ‚îÇ  ALTERNATIVE: Re-encode entire video
‚îÇ ‚Ä¢ Optional upload/notify    ‚îÇ              (slower but more control)
‚îÇ                             ‚îÇ
‚îÇ                             ‚îÇ  PERFORMANCE: 10-30s
‚îî‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îò
  ‚îÇ
  ‚îÇ PipelineResult {
  ‚îÇ   success: true
  ‚îÇ   video_path: Path("output/final_video.mp4")
  ‚îÇ   total_duration: 120.5
  ‚îÇ   scene_count: 10
  ‚îÇ   timing_report: Path("output/timing_report.json")
  ‚îÇ   metadata: {
  ‚îÇ     total_size: "15.2 MB",
  ‚îÇ     resolution: "1920x1080",
  ‚îÇ     fps: 30,
  ‚îÇ     codec: "h264 (NVENC)"
  ‚îÇ   }
  ‚îÇ   warnings: ["Scene 3: Narration truncated to fit max_duration"]
  ‚îÇ   errors: []
  ‚îÇ }
  ‚îÇ
  ‚ñº
FINAL OUTPUT

TOTAL PIPELINE TIME: 2-8 minutes
TOTAL STAGES: 6 (7 with validation)
CHECKPOINTS: 6 (one per stage)
RESUME CAPABILITY: Yes, from any checkpoint
```

**Context Dictionary Accumulation:**
```python
# Initial context (Stage 0)
context = {
    "task_id": "task_abc123",
    "input_config": InputConfig(...)
}

# After Stage 1 (Input Adaptation)
context["video_config"] = VideoConfig(
    video_id="abc",
    scenes=[SceneConfig(...), ...]
)
context["input_metadata"] = {
    "source_type": "document",
    "pages": 5
}

# After Stage 2 (Content Parsing)
context["parsed_content"] = {
    "sections": [...],
    "templates": [...]
}

# After Stage 3 (Script Generation)
context["video_config"]  # Updated with narration scripts
# video_config.scenes[0].narration = "Welcome to..."

# After Stage 4 (Audio Generation)
context["audio_dir"] = Path("audio/video_abc_audio/")
context["timing_report"] = Path("audio/.../timing_report.json")
# video_config.scenes[0].audio_file = Path("scene_1.mp3")
# video_config.scenes[0].final_duration = 4.2

# After Stage 5 (Video Generation)
context["video_segments"] = [
    Path("video/scene_1.mp4"),
    Path("video/scene_2.mp4"),
    ...
]

# After Stage 6 (Output Handling)
context["final_video_path"] = Path("output/final_video.mp4")
context["metadata"] = {...}
```

**Design Pattern: Context Accumulation**
- **Why:** Allows stages to access outputs from previous stages
- **How:** Each stage adds to shared context dictionary
- **Benefit:** Loose coupling between stages
- **Trade-off:** Less type-safe than explicit parameters (mitigated with validation)

---

## Dependencies

### Internal (Clean)
- `stages/` ‚Üí `pipeline.stage` ‚úÖ
- All ‚Üí `shared/models` ‚úÖ
- All ‚Üí `shared/config` ‚úÖ

### External (Issues)
- `video_generator/` ‚Üí `scripts/generate_documentation_videos.py` ‚ö†Ô∏è
- 3 modules ‚Üí old `config.py` ‚ö†Ô∏è
- 2 modules ‚Üí old `exceptions.py` ‚ö†Ô∏è

---

## Metrics

| Metric | Value | Status |
|--------|-------|--------|
| Modularity | 8/10 | ‚úÖ Good |
| Separation of Concerns | 9/10 | ‚úÖ Excellent |
| Coupling | 7/10 | ‚ö†Ô∏è Medium (external deps) |
| Cohesion | 9/10 | ‚úÖ Excellent |
| SOLID Compliance | 8/10 | ‚úÖ Good |
| Testability | 7/10 | ‚ö†Ô∏è Needs DI improvements |

---

## Recommended Actions

### Week 1-2 (Critical)
1. ‚úÖ Consolidate config modules
2. ‚úÖ Consolidate exception modules
3. ‚úÖ Internalize scene rendering functions

### Week 3-4 (High Priority)
4. Add dependency injection to stages
5. Refactor large files (>500 LOC)
6. Add unit tests (target 80% coverage)

### Month 2 (Medium Priority)
7. Remove hardcoded file paths
8. Add plugin system for extensibility
9. Improve type safety with mypy

---

## Quick Architecture Decisions

### Why Pipeline Pattern?
- Video generation is inherently sequential
- Each stage builds on previous artifacts
- Easy to understand and debug
- Supports resume from failure

### Why Adapter Pattern for Inputs?
- Multiple input formats (PDF, YAML, YouTube, etc.)
- Need consistent output (VideoConfig)
- Easy to add new formats

### Why Event System?
- Real-time progress tracking
- Decouples UI from pipeline
- Supports multiple listeners (UI, logging, metrics)

### Why State Persistence?
- Long-running operations (5-15 minutes)
- Resume after failure
- Track progress across sessions

---

## Testing Strategy

### Unit Tests (Target: 85%)
```python
# Test each stage in isolation
async def test_audio_generation_stage():
    stage = AudioGenerationStage()
    context = {"video_config": mock_video_config}
    result = await stage.execute(context)
    assert result.success
```

### Integration Tests (Target: 70%)
```python
# Test complete pipeline
async def test_complete_pipeline():
    pipeline = create_complete_pipeline()
    result = await pipeline.execute(input_config)
    assert result.video_path.exists()
```

### Mock External Dependencies
- Edge TTS API
- FFmpeg commands
- File I/O

---

## Common Questions

**Q: Can I add a new input format?**
A: Yes! Implement `InputAdapter` interface and register in `InputStage`.

**Q: How do I track progress in real-time?**
A: Subscribe to events via `EventEmitter.on()` or `on_async()`.

**Q: Can I resume a failed pipeline?**
A: Yes! Use `pipeline.execute(input_config, resume=True)`.

**Q: How do I add a new processing step?**
A: Create a new `Stage` subclass and register it in the pipeline.

**Q: Why are there two config files?**
A: Technical debt from refactoring. Use `shared/config.py` (consolidation in progress).

---

## File Organization Best Practices

### ‚úÖ Do:
- Put models in `shared/models.py`
- Put config in `shared/config.py`
- Put exceptions in `shared/exceptions.py`
- Create stages in `stages/` directory
- Create adapters in `input_adapters/` directory

### ‚ùå Don't:
- Import from `scripts/` directory
- Hardcode file paths
- Create circular dependencies
- Skip type hints
- Mix concerns in one file

---

## Performance Characteristics

| Operation | Time | Bottleneck |
|-----------|------|------------|
| Input Adaptation | <1s | File I/O |
| Content Parsing | 1-5s | Markdown parsing |
| Script Generation | 2-10s | AI enhancement (if enabled) |
| Audio Generation | 30s-2min | Edge TTS API calls |
| Video Rendering | 1-5min | FFmpeg encoding |
| Output Handling | 10-30s | File concatenation |

**Total Pipeline:** 2-8 minutes for typical video (10-20 scenes)

**Optimizations:**
- ‚úÖ NumPy-accelerated frame blending (10x faster)
- ‚úÖ GPU encoding with NVENC
- ‚ö†Ô∏è Sequential audio generation (can be parallelized)
- ‚ö†Ô∏è JSON state saves on every stage (can be batched)

---

## External Dependencies

| Library | Purpose | Replaceability |
|---------|---------|---------------|
| Edge TTS | Text-to-speech | Medium (can use other TTS) |
| FFmpeg | Video encoding | Low (industry standard) |
| NumPy | Fast math operations | Medium (can use PIL) |
| Pillow | Image manipulation | Low (common) |
| Asyncio | Async execution | Low (core Python) |

---

## Security Considerations

### Input Validation ‚ö†Ô∏è
- File paths from user input need sanitization
- URL validation in YouTube adapter
- YAML schema validation exists but not comprehensive

### API Keys ‚úÖ
- Loaded from environment variables
- Not hardcoded in source

### Error Messages ‚ö†Ô∏è
- May leak file paths in production
- Recommendation: Sanitize error messages for prod

---

## Deployment Readiness

| Aspect | Status | Notes |
|--------|--------|-------|
| Configuration | ‚ö†Ô∏è Partial | Environment variables supported, but hardcoded paths exist |
| Error Handling | ‚úÖ Good | Graceful degradation, resume capability |
| Logging | ‚úÖ Good | Structured logging with levels |
| State Persistence | ‚úÖ Excellent | Production-ready |
| Monitoring | ‚ö†Ô∏è Basic | Event system exists, needs metrics export |
| Testing | ‚ùå Missing | No tests currently |
| Documentation | ‚úÖ Excellent | Comprehensive docs/ directory |

---

## Next Steps

1. **Read full analysis:** See `ARCHITECTURE_ANALYSIS.md` for detailed findings
2. **Review component diagrams:** See `COMPONENT_DIAGRAM.md` for visual architecture
3. **Start refactoring:** Begin with config/exception consolidation (highest ROI)
4. **Add tests:** Start with unit tests for stages (easiest to test)
5. **Improve DI:** Add dependency injection for better testability

---

**Questions?** See `ARCHITECTURE_ANALYSIS.md` for detailed explanations.

**Generated:** 2025-10-05 by Claude Code Architecture Analysis Agent
